{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook aims to recommend a possible date that the user will like\n",
    "# The main idea is for the user to enter his/her iid (unique id in the study), then we will find the people whom\n",
    "# he/she has dated. We split this matrix into half and half as rated and unrated (pretend they are not rated), and \n",
    "# give each of the unrated date a predicted rating. We sort the ratings and recommend the highest 3 to the user.\n",
    "# Finally, we evaluate this system by computing RMSE between predicted ratings and the real ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "import numpy as np # linear algebra\n",
    "from numpy import linalg as la\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "data = pd.read_csv(\"Speed Dating Data.csv\", encoding=\"ISO-8859-1\")\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(all_dates, input_vars):\n",
    "    # preprocessing, dealing with NaN cells\n",
    "    median_features = all_dates.loc[:, input_vars].dropna().median()\n",
    "    features = all_dates.loc[:, input_vars].fillna(median_features) # use median to fill the NaN values\n",
    "    like = features.like_o\n",
    "    print(features.shape)\n",
    "    return features, like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim(row1, row2): # cos similarity\n",
    "    num = row1.transpose().dot(row2)\n",
    "    denom = la.norm(row1)*la.norm(row2)\n",
    "    sim = 0.5+0.5*(num/denom)\n",
    "#     print(\"The similarity is: \"+str(sim))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(rated_dates, unrated_dates, rated_like, unrated_like):\n",
    "    m = unrated_dates.shape[0]\n",
    "    n = rated_dates.shape[0]\n",
    "    print(\"m: \"+str(m)+\"; n: \"+str(n))\n",
    "    predicted_like = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        sim_sum = 0\n",
    "        rat_sim_sum = 0\n",
    "        for j in range(n):\n",
    "            unrated = unrated_dates.as_matrix()[i,:]\n",
    "            rated = rated_dates.as_matrix()[j,:]\n",
    "            similarity = sim(unrated, rated)\n",
    "            sim_sum += similarity\n",
    "            rat_sim_sum += rated_like.values[j]*similarity\n",
    "        predicted_like[i] = rat_sim_sum/sim_sum\n",
    "    print(\"RMSE: \"+str(sqrt(mean_squared_error(unrated_like, predicted_like))))\n",
    "    return predicted_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recommend(iid, data):\n",
    "    all_dates = data.loc[data['pid'] == iid] # raw matrix containing information for all dates\n",
    "    # vars in interest from the last notebook, including scores of 6 main attributes given by partner, and 17 lifestyle scores\n",
    "    input_vars1 = ['attr_o', 'sinc_o', 'intel_o','fun_o','amb_o','shar_o', 'sports','tvsports','exercise','dining','museums','art','hiking','gaming','clubbing','reading','tv','theater','movies','concerts','music','shopping','yoga']\n",
    "    # gender and order\n",
    "    input_vars2 = ['gender', 'ptn_order']\n",
    "    # How they value the 6 main attributes during signup stage (stage 1)\n",
    "    input_vars3 = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "    # How they value the 6 main attributes after the event (stage 2)\n",
    "    input_vars4 = ['attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2']\n",
    "    # How they value the 6 main attributes after being sent their matches (stage 3)\n",
    "    input_vars5 = ['attr1_3', 'sinc1_3', 'intel1_3', 'fun1_3', 'amb1_3', 'shar1_3']\n",
    "    input_vars = input_vars1+input_vars2+input_vars3+input_vars4+input_vars5\n",
    "    # In this system we also need 'like_o' and iid!! (like_o is how this user likes his/her dates from dates data)\n",
    "    input_vars = input_vars + ['like_o', 'iid']\n",
    "    \n",
    "    features, like = preprocess(all_dates, input_vars)\n",
    "    features = features.drop('like_o', 1)\n",
    "    \n",
    "    # random split\n",
    "    rated_dates, unrated_dates, rated_like, unrated_like = train_test_split(\n",
    "        features, like, test_size=0.50, random_state=0) # half and half\n",
    "    # predict\n",
    "    predicted_like = predict(rated_dates, unrated_dates, rated_like, unrated_like.values)\n",
    "    \n",
    "    # sort and recommend top 3\n",
    "    # print(predicted_like)\n",
    "    sorted_like = np.sort(predicted_like)[::-1]\n",
    "    # print(sorted_like)\n",
    "    for i in range(len(predicted_like)):\n",
    "        if (predicted_like[i] == sorted_like[0]): \n",
    "            print(\"First recommendation: No. \"+ str(int(unrated_dates.iloc[i,:].iid))+\"; predicted rating: \"+ str(predicted_like[i])+\"; real rating: \"+ str(unrated_like.values[i]))\n",
    "        elif (predicted_like[i] == sorted_like[1]): \n",
    "            print(\"Second recommendation: No. \"+ str(int(unrated_dates.iloc[i,:].iid))+\"; predicted rating: \"+ str(predicted_like[i])+\"; real rating: \"+ str(unrated_like.values[i]))\n",
    "        elif (predicted_like[i] == sorted_like[2]): \n",
    "            print(\"Third recommendation: No. \"+ str(int(unrated_dates.iloc[i,:].iid))+\"; predicted rating: \"+ str(predicted_like[i])+\"; real rating: \"+ str(unrated_like.values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 45)\n",
      "m: 10; n: 9\n",
      "RMSE: 0.9540783187899158\n",
      "First recommendation: No. 31; predicted rating: 6.67553868596; real rating: 8.0\n",
      "Second recommendation: No. 29; predicted rating: 6.67065530869; real rating: 7.0\n",
      "Third recommendation: No. 25; predicted rating: 6.667808211; real rating: 7.0\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "recommend(45, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good!! The real ratings fit what we have in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSE < 1, meaning our predicted rating is within an error of 1. Considering 'like' ranges from 1-10, \n",
    "# this is pretty good result!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 45)\n",
      "m: 5; n: 5\n",
      "RMSE: 0.3949382481857712\n",
      "Second recommendation: No. 64; predicted rating: 5.68041865239; real rating: 6.0\n",
      "Third recommendation: No. 60; predicted rating: 5.67976334621; real rating: 6.0\n",
      "First recommendation: No. 65; predicted rating: 5.69722294408; real rating: 6.0\n"
     ]
    }
   ],
   "source": [
    "# another demo\n",
    "recommend(67, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 45)\n",
      "m: 5; n: 5\n",
      "RMSE: 2.4968321992268807\n",
      "First recommendation: No. 74; predicted rating: 4.42647241456; real rating: 3.0\n",
      "Third recommendation: No. 70; predicted rating: 4.39892108304; real rating: 9.0\n",
      "Second recommendation: No. 67; predicted rating: 4.40979879981; real rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# another demo\n",
    "recommend(56, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSE not so stable, due to small date size. (This user only dates 10 people and rates 10 people.) \n",
    "# Still, this method works! If given larger dataset, we can do better."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
